{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4agent-header",
   "metadata": {},
   "source": [
    "# Customer Service Assistant - Multi-Agents RAG System\n",
    "\n",
    "This project implements a customer service assistant that answers product-related queries using a multi-agents RAG system:\n",
    "\n",
    "1. **Agent 1**: Document Loader & Query Embedding Agent\n",
    "2. **Agent 2a**: Query Processing Agent (enhances user queries)\n",
    "3. **Agent 2b**: Document Retrieval Agent (finds relevant documents)\n",
    "4. **Agent 3**: Response Generation Agent (generates final answers)\n",
    "\n",
    "**Key Features:**\n",
    "- Uses local sentence transformers for embeddings (no OpenAI quota needed)\n",
    "- ChromaDB for vector storage\n",
    "- Enhanced query processing for better retrieval\n",
    "- Context-aware response generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import uuid\n",
    "from docx import Document\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "\n",
    "print(\"Installing required packages if needed...\")\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    print(\"✓ sentence-transformers already installed\")\n",
    "except ImportError:\n",
    "    print(\"Installing sentence-transformers...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"sentence-transformers\"])\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    print(\"✓ sentence-transformers installed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-embeddings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load local embedding model\n",
    "print(\"Loading local embedding model...\")\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(\"✓ Embedding model loaded successfully!\")\n",
    "print(f\"Model: {embedding_model.get_sentence_embedding_dimension()} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agent1-document-loader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 1: Document Loader Agent\n",
    "def load_docx_chunks(doc_path):\n",
    "    \"\"\"Load and parse Word document into chunks with category information\"\"\"\n",
    "    print(f\"Loading document: {doc_path}\")\n",
    "    doc = Document(doc_path)\n",
    "    chunks = []\n",
    "    current_category = \"\"\n",
    "\n",
    "    for para in doc.paragraphs:\n",
    "        if para.style.name.startswith(\"Heading\"):\n",
    "            current_category = para.text.strip()\n",
    "        elif para.text.strip():\n",
    "            full_text = f\"{current_category}: {para.text.strip()}\" if current_category else para.text.strip()\n",
    "            chunks.append(full_text)\n",
    "    \n",
    "    print(f\"✓ Loaded {len(chunks)} text chunks from document\")\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agent1-embedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 1: Query Embedding Agent\n",
    "def embed_query(query):\n",
    "    \"\"\"Generate embeddings for user queries using local model\"\"\"\n",
    "    return embedding_model.encode(query).tolist()\n",
    "\n",
    "# Test the embedding function\n",
    "test_query = \"What is the price of iPhone 15?\"\n",
    "test_embedding = embed_query(test_query)\n",
    "print(f\"✓ Test embedding generated: {len(test_embedding)} dimensions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build-knowledge-base",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Knowledge Base with ChromaDB\n",
    "def build_knowledge_base(chunks, collection_name=\"chat_memory_4agents\"):\n",
    "    \"\"\"Create and populate ChromaDB collection with document embeddings\"\"\"\n",
    "    print(f\"Building knowledge base with collection: {collection_name}\")\n",
    "    \n",
    "    client = chromadb.PersistentClient(\n",
    "        path = \"./chroma_db\",\n",
    "        settings = Settings(anonymized_telemetry=False))\n",
    "    \n",
    "    # Get or create collection\n",
    "    try:\n",
    "        collection = client.get_collection(name=collection_name)\n",
    "        print(f\"✓ Using existing collection: {collection_name}\")\n",
    "    except:\n",
    "        collection = client.create_collection(name=collection_name)\n",
    "        print(f\"✓ Created new collection: {collection_name}\")\n",
    "    \n",
    "    # Check if collection already has documents\n",
    "    count = collection.count()\n",
    "    if count > 0:\n",
    "        print(f\"✓ Collection already contains {count} documents\")\n",
    "        return collection\n",
    "    \n",
    "    print(f\"Creating embeddings for {len(chunks)} chunks...\")\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Use local embedding model\n",
    "        embedding = embedding_model.encode(chunk).tolist()\n",
    "        collection.add(documents=[chunk], embeddings=[embedding], ids=[str(uuid.uuid4())])\n",
    "        \n",
    "        if (i + 1) % 5 == 0:\n",
    "            print(f\"  Processed {i + 1}/{len(chunks)} chunks...\")\n",
    "\n",
    "    print(\"✓ Knowledge base built successfully!\")\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agent2a-query-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 2a: Query Processing Agent\n",
    "def process_query(query):\n",
    "    \"\"\"Process and enhance user queries for better retrieval\"\"\"\n",
    "    print(f\"\\n Processing query: '{query}'\")\n",
    "    \n",
    "    # Clean and normalize the query\n",
    "    processed_query = query.strip().lower()\n",
    "    \n",
    "    # Extract key terms for better search\n",
    "    key_terms = []\n",
    "    if \"price\" in processed_query or \"cost\" in processed_query:\n",
    "        key_terms.append(\"pricing\")\n",
    "    if \"iphone\" in processed_query:\n",
    "        key_terms.append(\"iphone\")\n",
    "    if \"mac\" in processed_query:\n",
    "        key_terms.append(\"mac\")\n",
    "    if \"watch\" in processed_query:\n",
    "        key_terms.append(\"watch\")\n",
    "    if \"ipad\" in processed_query:\n",
    "        key_terms.append(\"ipad\")\n",
    "    if \"airpods\" in processed_query:\n",
    "        key_terms.append(\"airpods\")\n",
    "    \n",
    "    # Create enhanced query\n",
    "    enhanced_query = query\n",
    "    if key_terms:\n",
    "        enhanced_query = f\"{query} {' '.join(key_terms)}\"\n",
    "    \n",
    "    print(f\"✓ Query enhanced: '{query}' → '{enhanced_query}'\")\n",
    "    return enhanced_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agent2b-document-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 2b: Document Retrieval Agent\n",
    "def retrieve_documents(embedding, collection, k=3):\n",
    "    \"\"\"Retrieve relevant documents based on query embedding\"\"\"\n",
    "    print(f\" Searching for {k} most relevant documents...\")\n",
    "    \n",
    "    try:\n",
    "        # Perform vector similarity search\n",
    "        results = collection.query(query_embeddings=[embedding], n_results=k)\n",
    "        docs = results.get(\"documents\", [[]])[0]\n",
    "        \n",
    "        # Process and rank results\n",
    "        if docs:\n",
    "            print(f\"✓ Found {len(docs)} relevant documents\")\n",
    "            # Join documents with separators for better readability\n",
    "            formatted_docs = \"\\n---\\n\".join(docs)\n",
    "            return formatted_docs\n",
    "        else:\n",
    "            print(\"⚠ No relevant documents found\")\n",
    "            return \"\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\" Error retrieving documents: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agent3-response-generation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 3: Response Generation Agent\n",
    "def generate_response(context, user_input):\n",
    "    \"\"\"Generate human-like responses based on retrieved context\"\"\"\n",
    "    print(f\"\\n Generating response for: '{user_input}'\")\n",
    "    \n",
    "    if not context:\n",
    "        return \"I'm sorry, I couldn't find relevant information to answer your question. Could you please rephrase or ask about a different Apple product?\"\n",
    "    \n",
    "    # Create a comprehensive response based on context\n",
    "    response_parts = []\n",
    "    \n",
    "    # Extract key information from context\n",
    "    context_lines = context.split(\"\\n---\\n\")\n",
    "    \n",
    "    for line in context_lines:\n",
    "        if line.strip():\n",
    "            # Clean up the line and add to response\n",
    "            clean_line = line.strip()\n",
    "            if clean_line and len(clean_line) > 10:  # Only add substantial content\n",
    "                response_parts.append(clean_line)\n",
    "    \n",
    "    if response_parts:\n",
    "        # Combine the most relevant information\n",
    "        response = \"\\n\\n\".join(response_parts[:2])  # Limit to top 2 most relevant pieces\n",
    "        \n",
    "        # Add a helpful conclusion\n",
    "        response += \"\\n\\nThis information should help answer your question about Apple products. Is there anything specific you'd like to know more about?\"\n",
    "        \n",
    "        return response\n",
    "    else:\n",
    "        return \"I found some information but it wasn't specific enough to answer your question. Could you please ask about a specific Apple product or feature?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controller-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controller Function - Orchestrates all agents\n",
    "def run_multi_agent_rag_system(doc_path):\n",
    "    \"\"\"Main function that coordinates all agents\"\"\"\n",
    "    print(\" Starting multi-Agent RAG System...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Agent 1: Load documents and prepare embeddings\n",
    "    print(\"\\n Agent 1: Document Loader & Embedding Agent\")\n",
    "    chunks = load_docx_chunks(doc_path)\n",
    "    \n",
    "    # Build knowledge base\n",
    "    print(\"\\n Building Knowledge Base...\")\n",
    "    collection = build_knowledge_base(chunks)\n",
    "    \n",
    "    print(\"\\n Customer service assistant (multi-Agent RAG system) ready!\")\n",
    "    print(\"Ask product-related questions about Apple products.\")\n",
    "    print(\"Type 'exit', 'quit', or 'bye' to end the session.\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user_input = input(\"\\n You: \").strip()\n",
    "            \n",
    "            if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "                print(\"\\n Customer Assistant: Thank you! Have a great day! \")\n",
    "                break\n",
    "\n",
    "            if not user_input:\n",
    "                print(\"Please enter a question about Apple products.\")\n",
    "                continue\n",
    "\n",
    "            # Agent 2a: Process and enhance the query\n",
    "            enhanced_query = process_query(user_input)\n",
    "            \n",
    "            # Agent 1: Generate embedding for enhanced query\n",
    "            embedding = embed_query(enhanced_query)\n",
    "\n",
    "            # Agent 2b: Search for relevant documents\n",
    "            context = retrieve_documents(embedding, collection)\n",
    "\n",
    "            # Agent 3: Generate response using context\n",
    "            response = generate_response(context, user_input)\n",
    "            \n",
    "            print(f\"\\n Customer Assistant: {response}\")\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\n\\n Customer Assistant: Session interrupted. Goodbye! \")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\n Error: {e}\")\n",
    "            print(\"Please try asking your question again.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-document-path",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the document path\n",
# Configuration - Update these paths for your environment
print("Configuration Settings:")
print("=" * 50)

# Update these paths according to your setup
DOC_PATH = "./apple_product_prices_2025.docx"  # Path to your Word document
DB_PATH = "./chroma_db"  # Path for ChromaDB storage

print(f"Document path: {DOC_PATH}")
print(f"Database path: {DB_PATH}")
print(f"Document exists: {os.path.exists(DOC_PATH)}")
print("\nNote: Update DOC_PATH and DB_PATH variables above if needed!")
    "doc_path = \"./chroma_db/apple_product_prices_2025.docx\"\n",
    "print(f\" Document path: {doc_path}\")\n",
    "print(f\" File exists: {os.path.exists(doc_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test-individual-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test individual functions to ensure they work\n",
    "print(\" Testing individual functions...\")\n",
    "\n",
    "# Test document loading\n",
    "print(\"\\n1. Testing document loading...\")\n",
    "chunks = load_docx_chunks(doc_path)\n",
    "print(f\"   ✓ Loaded {len(chunks)} chunks\")\n",
    "\n",
    "# Test query processing\n",
    "print(\"\\n2. Testing query processing...\")\n",
    "test_query = \"What is the price of iPhone 15?\"\n",
    "enhanced = process_query(test_query)\n",
    "print(f\"   ✓ Query enhanced: {enhanced}\")\n",
    "\n",
    "# Test embedding\n",
    "print(\"\\n3. Testing embedding generation...\")\n",
    "embedding = embed_query(test_query)\n",
    "print(f\"   ✓ Embedding generated: {len(embedding)} dimensions\")\n",
    "\n",
    "print(\"\\n All individual functions tested successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the multi-Agents RAG System\n",
    "print(\" Launching Multi-Agents RAG System...\")\n",
    "run_multi_agent_rag_system(doc_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
